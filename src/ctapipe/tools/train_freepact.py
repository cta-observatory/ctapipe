"""
Tool for training a Pixel Classifier using a Keras MLP.
"""

import astropy.units as u
import numpy as np
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

from ctapipe.core import Tool
from ctapipe.core.traits import Float, Int, IntTelescopeParameter, List, Path
from ctapipe.image import dilate, tailcuts_clean
from ctapipe.io import TableLoader
from ctapipe.utils.template_network_interpolator import custom_symlog

__all__ = ["TrainFreePACT"]


class TrainFreePACT(Tool):
    """
    Tool to train a pixel classifier (FreePACT) MLP on dl1 images.

    The tool loads DL1 images and true shower parameters, constructs a
    pixel-wise dataset (Signal vs Background), and trains an MLP classifier.
    Background is generated by shuffling amplitudes.
    """

    name = "ctapipe-train-freepact"
    description = __doc__

    output_path = Path(
        directory_ok=False,
        help="Output path for the trained model (Keras format).",
    ).tag(config=True)

    n_events = IntTelescopeParameter(
        default_value=None,
        allow_none=True,
        help=(
            "Number of events to use for training per telescope type."
            " If not given, all available events will be used."
        ),
    ).tag(config=True)

    batch_size = Int(
        default_value=100000,
        help="Batch size for training.",
    ).tag(config=True)

    epochs = Int(
        default_value=100,
        help="Number of training epochs.",
    ).tag(config=True)

    chunk_size = Int(
        default_value=10000,
        help="Number of events to load at once.",
    ).tag(config=True)

    limit = Int(
        default_value=None,
        allow_none=True,
        help="Limit on images used in training",
    ).tag(config=True)

    reweight_index = Float(
        default_value=0,
        allow_none=True,
        help="Index for reweighting events by energy",
    ).tag(config=True)

    reweight_energy = Float(
        default_value=1,
        allow_none=True,
        help="Energy for reweighting events by energy",
    ).tag(config=True)

    input_url = List(
        Path(exists=True, directory_ok=False),
        default_value=[],
        help="Input DL1 files",
    ).tag(config=True)

    layer_number = Int(
        default_value=10,
        help="Number of hidden layers in the MLP.",
    ).tag(config=True)

    layer_neurons = Int(
        default_value=50,
        help="Number of neurons in each hidden layer.",
    ).tag(config=True)

    tailcut_threshold1 = Float(
        default_value=10,
        help="Threshold 1 for tailcut cleaning.",
    ).tag(config=True)

    tailcut_threshold2 = Float(
        default_value=5,
        help="Threshold 2 for tailcut cleaning.",
    ).tag(config=True)

    tailcut_additional_rows = Int(
        default_value=4,
        help="Additional rows to clean around the core.",
    ).tag(config=True)

    aliases = {
        ("i", "input"): "TrainFreePACT.input_url",
        ("o", "output"): "TrainFreePACT.output_path",
        "epochs": "TrainFreePACT.epochs",
        "n_events": "TrainFreePACT.n_events",
        "batch_size": "TrainFreePACT.batch_size",
        "chunk_size": "TrainFreePACT.chunk_size",
        "imagelimit": "TrainFreePACT.limit",
        "reweight_index": "TrainFreePACT.reweight_index",
        "reweight_energy": "TrainFreePACT.reweight_energy",
        "layer_number": "TrainFreePACT.layer_number",
        "layer_neurons": "TrainFreePACT.layer_neurons",
    }

    classes = [TableLoader]

    def setup(self):
        """Initialize components."""
        # Check for tensorflow
        try:
            import tensorflow  # noqa: F401
        except ImportError:
            self.log.critical("tensorflow is required for this tool.")
            self.exit(1)

        if not self.input_url:
            self.log.critical("Specifying input file(s) is required.")
            self.exit(1)

        # Open the first file to get the subarray description
        # We assume all files have the same subarray
        try:
            with TableLoader(
                input_url=self.input_url[0],
                parent=self,
                dl1_images=True,
                simulated=True,
                true_parameters=True,
                instrument=True,
            ) as loader:
                self.subarray = loader.subarray
        except Exception as e:
            self.log.critical(f"Could not read subarray from first file: {e}")
            self.exit(1)

        if self.output_path is None:
            self.log.critical("Output path is required via -o / --output.")
            self.exit(1)

    def start(self):
        """Load data and train models."""
        # We will train one model per telescope type

        types = self.subarray.telescope_types
        self.log.info("Found telescope types: %s", types)

        for tel_type in types:
            self.log.info("Processing telescope type: %s", tel_type)
            X, y = self._load_and_process_data(tel_type)

            if len(X) == 0:
                self.log.warning("No data found for %s", tel_type)
                continue

            self.log.info(
                "Training model for %s with %d samples (batch_size=%d, epochs=%d)",
                tel_type,
                len(X),
                self.batch_size,
                self.epochs,
            )

            model = self._build_model(
                input_shape=(X.shape[1],),
                layer_number=self.layer_number,
                layer_neurons=self.layer_neurons,
            )
            out_name = str(self.output_path).replace(".keras", "").replace(".h5", "")
            save_path = f"{out_name}_{tel_type}.keras"

            callbacks = [
                EarlyStopping(
                    monitor="val_loss", patience=50, verbose=1, start_from_epoch=50
                ),
                ReduceLROnPlateau(
                    monitor="val_loss",
                    factor=0.5,
                    patience=20,
                    verbose=1,
                    start_from_epoch=50,
                ),
                ModelCheckpoint(
                    filepath=save_path,
                    monitor="val_loss",
                    save_best_only=True,
                    verbose=1,
                ),
            ]
            model.fit(
                X,
                y,
                epochs=self.epochs,
                batch_size=self.batch_size,
                validation_split=0.1,
                verbose=1,
                callbacks=callbacks,
            )

            # Save model
            # Construct a filename for this telescope type
            # If the user provided a file path (e.g. model.keras), we might need to split it
            # or save a dictionary of models?
            # Keras models are usually saved as directories or files.
            # Let's append the telescope type to the output name.

            self.log.info("Saving model to %s", save_path)
            model.save(save_path)

    def _load_and_process_data(self, tel_type):
        """Read chunked data and create pixel-wise dataset."""
        from astropy.coordinates import AltAz, SkyCoord

        from ctapipe.coordinates import (
            CameraFrame,
            GroundFrame,
            NominalFrame,
            TiltedGroundFrame,
        )

        # Get camera geometry to map pixels to positions
        example_tel_id = None
        for tel_id, tel in self.subarray.tel.items():
            if str(tel) == str(tel_type):
                example_tel_id = tel_id
                break

        if example_tel_id is None:
            # Try matching by string representation if direct comparison failed
            for tel_id, tel in self.subarray.tel.items():
                if str(tel) == str(tel_type):
                    example_tel_id = tel_id
                    break

        if example_tel_id is None:
            self.log.error("Could not find telescope for type %s", tel_type)
            return np.array([]), np.array([])

        geometry = self.subarray.tel[example_tel_id].camera.geometry
        focal_length = self.subarray.tel[example_tel_id].optics.effective_focal_length

        pix_x = geometry.pix_x
        pix_y = geometry.pix_y

        pixel_features_list = []
        n_loaded = 0

        for input_file in self.input_url:
            self.log.info("Loading data from %s", input_file)

            with TableLoader(
                input_url=input_file,
                parent=self,
                dl1_images=True,
                simulated=True,
                true_parameters=True,
                instrument=True,
                pointing=True,
                dl1_parameters=False,
            ) as loader:
                # Iterate over chunks
                iterator = loader.read_telescope_events_chunked(
                    chunk_size=self.chunk_size,
                    telescopes=[tel_type],
                    dl1_images=True,
                    dl1_parameters=False,
                    simulated=True,
                    true_parameters=True,
                    instrument=True,
                    pointing=True,
                )

                for chunk in iterator:
                    data = chunk.data
                    if len(data) == 0:
                        continue

                    # Extract features
                    images = data["image"]
                    mask_array = np.zeros(images.shape, dtype=bool)

                    for i in range(len(images)):
                        mask = tailcuts_clean(
                            geometry,
                            images[i],
                            self.tailcut_threshold1,
                            self.tailcut_threshold2,
                        )
                        for j in range(self.tailcut_additional_rows):
                            mask = dilate(geometry, mask)
                        mask_array[i] = mask

                    energies = data["true_energy"].quantity.to_value(u.TeV)
                    if self.reweight_index != 0:
                        weight_factor = (
                            energies / (self.reweight_energy * u.TeV)
                        ) ** self.reweight_index
                        random_value = np.random.rand(mask_array.shape[0])
                        reweight_mask = random_value < weight_factor.value
                        mask_array = np.logical_and(
                            mask_array, reweight_mask[:, np.newaxis]
                        )

                    core_x = data["true_core_x"].quantity
                    core_y = data["true_core_y"].quantity
                    true_zenith = 90 * u.deg - data["true_alt"].quantity

                    # X max
                    if "true_x_max" in data.colnames:
                        x_max = data["true_x_max"].quantity.to_value(u.g / (u.cm**2))
                        x_max /= np.cos(true_zenith)  # convert to slant depth
                    else:
                        x_max = np.zeros(len(data))
                        if (
                            "true_h_max" not in data.colnames
                        ):  # Avoid redundant warnings
                            self.log.warning("true_x_max not found, using 0")

                    # Telescope position
                    # TableLoader with instrument=True usually adds pos_x, pos_y, pos_z in GroundFrame
                    if "pos_x" in data.colnames:
                        tel_x = data["pos_x"].quantity
                        tel_y = data["pos_y"].quantity
                        tel_z = data["pos_z"].quantity
                    else:
                        # Fallback to older names if necessary, but user suggested 'pos_x'
                        tel_x = data["tel_pos_x"].quantity
                        tel_y = data["tel_pos_y"].quantity
                        tel_z = data["tel_pos_z"].quantity

                    # Tilted Frame Transformation
                    # correct core and telescope positions to be in the tilted frame
                    pointing_alt = data["telescope_pointing_altitude"].quantity
                    pointing_az = data["telescope_pointing_azimuth"].quantity

                    p_dir = AltAz(alt=pointing_alt, az=pointing_az)
                    tilted_frame = TiltedGroundFrame(pointing_direction=p_dir)
                    # nominal_frame not needed here specifically, we do it per pixel

                    # Transform Core
                    # GroundFrame -> TiltedGroundFrame
                    # We assume core_z = 0 for the core position on ground?
                    # Usually true_core is on the ground plane (z=0 in GroundFrame).
                    core_ground = SkyCoord(
                        x=core_x, y=core_y, z=0 * u.m, frame=GroundFrame()
                    )
                    core_tilted = core_ground.transform_to(tilted_frame)
                    core_acc_x = core_tilted.x.to_value(u.m)
                    core_acc_y = core_tilted.y.to_value(u.m)

                    # Transform Telescope Position
                    tel_ground = SkyCoord(
                        x=tel_x, y=tel_y, z=tel_z, frame=GroundFrame()
                    )
                    tel_tilted = tel_ground.transform_to(tilted_frame)
                    tel_acc_x = tel_tilted.x.to_value(u.m)
                    tel_acc_y = tel_tilted.y.to_value(u.m)

                    # Calculate impact distance in Tilted Frame
                    dx = core_acc_x - tel_acc_x
                    dy = core_acc_y - tel_acc_y
                    phi = np.arctan2(dy, dx)
                    impact = np.sqrt(dx**2 + dy**2)

                    # Memory Optimization: Use mask indices instead of tiling
                    # Get indices of valid pixels (rows=event_idx, cols=pixel_idx)
                    rows, cols = np.nonzero(mask_array)

                    # Select features for valid pixels
                    energies_sel = energies[rows]
                    impact_sel = impact[rows]
                    xmax_sel = x_max[rows]

                    # Transform Camera Coordinates to Nominal Frame for valid pixels
                    # We need to construct the pointing for each valid pixel
                    pointing_alt_sel = pointing_alt[rows]
                    pointing_az_sel = pointing_az[rows]
                    pointing_sel = AltAz(alt=pointing_alt_sel, az=pointing_az_sel)

                    # Construct frames for each valid pixel (vectorized)
                    # Note: CameraFrame and NominalFrame can broadcast their parameters
                    cam_frame = CameraFrame(
                        focal_length=focal_length, telescope_pointing=pointing_sel
                    )
                    nom_frame = NominalFrame(origin=pointing_sel)

                    pixel_coords = SkyCoord(
                        x=pix_x[cols], y=pix_y[cols], frame=cam_frame
                    )
                    pixel_nominal = pixel_coords.transform_to(nom_frame)

                    pix_lon_sel = pixel_nominal.fov_lon.to_value(u.deg)
                    pix_lat_sel = pixel_nominal.fov_lat.to_value(u.deg)

                    # Select Source Position and Rotation Angle
                    # source_x/y and phi are per event (Radians)
                    # We need source position in Nominal Frame too to calculate rotation
                    source_alt_sel = data["true_alt"].quantity[rows]
                    source_az_sel = data["true_az"].quantity[rows]
                    source_sky_coord_sel = SkyCoord(
                        alt=source_alt_sel, az=source_az_sel, frame=AltAz()
                    )
                    source_nominal_sel = source_sky_coord_sel.transform_to(nom_frame)

                    source_x_sel = source_nominal_sel.fov_lon.to_value(u.deg)
                    source_y_sel = source_nominal_sel.fov_lat.to_value(u.deg)

                    phi_sel = phi[rows]

                    # Rotation center on source
                    diff_lon = pix_lon_sel - source_x_sel
                    diff_lat = pix_lat_sel - source_y_sel

                    # Rotate
                    cos_phi = np.cos(-phi_sel)
                    sin_phi = np.sin(-phi_sel)

                    pix_lon_rot = diff_lat * cos_phi - diff_lon * sin_phi
                    pix_lat_rot = diff_lat * sin_phi + diff_lon * cos_phi

                    # Select Images (Amplitudes)
                    images_sel = images[mask_array]

                    # Stack features
                    X_chunk = np.stack(
                        [
                            pix_lon_rot,
                            pix_lat_rot,
                            np.log10(energies_sel),
                            impact_sel / 100,
                            xmax_sel / 100,
                            custom_symlog(
                                np.array([images_sel / 10]), linear_threshold=2
                            ).ravel(),
                        ],
                        axis=1,
                    ).astype(np.float32)

                    pixel_features_list.append(X_chunk)
                    n_ev = np.sum(mask_array)

                    n_loaded += n_ev
                    if self.limit and n_loaded >= self.limit:
                        break

            if self.limit and n_loaded >= self.limit:
                break

        if not pixel_features_list:
            return np.array([]), np.array([])

        X_all = np.concatenate(pixel_features_list)
        # Dataset creation (Signal vs Background)
        n_total_pixels = len(X_all)
        n_samples = n_total_pixels // 2

        indices = np.random.choice(n_total_pixels, size=n_total_pixels, replace=False)
        indices_sig = indices[:n_samples]
        indices_bg = indices[n_samples : 2 * n_samples]

        X_sig = X_all[indices_sig]
        y_sig = np.ones(len(X_sig))

        X_bg = X_all[indices_bg].copy()
        np.random.shuffle(X_bg[:, 5])  # Shuffle amplitude
        y_bg = np.zeros(len(X_bg))

        X = np.concatenate([X_sig, X_bg])
        y = np.concatenate([y_sig, y_bg])

        train_idx = np.random.permutation(len(X))
        X = X[train_idx]
        y = y[train_idx]

        return X, y

    def _build_model(self, input_shape, layer_number=10, layer_neurons=50):
        """Build Keras MLP."""
        from tensorflow.keras.layers import Input

        layers = [Input(shape=input_shape)]

        for _ in range(layer_number):
            layers.append(Dense(layer_neurons, activation="swish"))

        layers.append(Dense(1, activation="sigmoid"))

        model = Sequential(layers)

        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss="binary_crossentropy",
            metrics=["accuracy"],
        )
        return model

    def finish(self):
        """Cleanup."""
        pass


def main():
    tool = TrainFreePACT()
    tool.run()


if __name__ == "__main__":
    main()
